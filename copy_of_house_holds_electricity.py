# -*- coding: utf-8 -*-
"""Copy of House_holds_electricity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XUbUAnmuEKqzhGE1nM1qsyOoTRgC6oA0

# Analyzing Household Power Consumption

### step 1: Problem statement

Predict the house hold electricity

### step 2: Data Acquisition
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error

data = pd.read_csv("/content/household_power_consumption.txt", sep=';')

data.info()

# remove ? values
data.replace('?', np.nan, inplace=True)

# data columns
numeric_columns = data.columns[2:]
data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric)

# DateTime
data['Datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], format='%d/%m/%Y %H:%M:%S')
data.drop(['Date', 'Time'], axis=1, inplace=True)

# Handling missing values
for column in numeric_columns:
    data[column] = data[column].fillna(data[column].mean())

# Normalization
scaler = MinMaxScaler()
data[numeric_columns] = scaler.fit_transform(data[numeric_columns])
data[numeric_columns].head()

"""## step 4: Exploratory Data Analysis(EDA)

### Data Visualization
"""

# Correlation heatmap
plt.figure(figsize=(10,8))
sns.heatmap(data[numeric_columns].corr(), annot=True, cmap="coolwarm")
plt.title('Correlation Matrix')
plt.show()

# corr() used for coeffiencient of correlation

"""## step 5: Feature Engineering"""

# new feature
data['Unmeasured_Energy'] = (data['Global_active_power'] * 1000 / 60 - \
                             data['Sub_metering_1'] -
                             data['Sub_metering_2'] -
                             data['Sub_metering_3'])
data['Hour'] = data['Datetime'].dt.hour
data['Day_of_Week'] = data['Datetime'].dt.dayofweek
data['Month'] = data['Datetime'].dt.month

data.head()

from sklearn.preprocessing import OneHotEncoder

categorical_cols = ['Hour', 'Day_of_Week', 'Month']
encoder = OneHotEncoder(drop='first', sparse_output=False)
data_encoded = encoder.fit_transform(data[categorical_cols])
data_encoded = pd.DataFrame(data_encoded, columns=encoder.get_feature_names_out(categorical_cols))
data_encoded.head()

"""## step:6 Modeling"""

data_numeric = data.drop(columns=categorical_cols)
data_processed = pd.concat([data_numeric, data_encoded], axis=1)
features = ['Global_reactive_power', 'Voltage', 'Global_intensity',
            'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3'] + [col for col in data_encoded.columns if 'Hour_' in col or 'Day_of_Week_' in col or 'Month_' in col]
X = data_processed[features]
y = data_processed['Global_active_power']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Linear Regression
reg_model = LinearRegression()
reg_model.fit(X_train, y_train)
y_pred = reg_model.predict(X_test)

"""## step 7: Model Evaluation"""

from sklearn.metrics import r2_score

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
adj_r2 = 1 - (1 - r2) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)

print("RMSE:",rmse)
print("MAE:", mae)
print("R-squared:", r2)
print("Adjusted R-squared:", adj_r2)

"""## Conclusion

Model performing well
"""